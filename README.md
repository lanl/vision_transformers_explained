[//]: <> (THIS IS A MARKDOWN FILE, VIEW IN A MARKDOWN VIEWER OR CONVERT)

# Vision Transformers Explained

This folder of code contains code and notebooks to supplement the Vision Transformers Explained series written by **Skylar Callis** for [*Towards Data Science*](https://towardsdatascience.com/). These articles can be read on Medium or in their equivalent Jupyter Notebook:

- [Vision Transformers, Explained](https://towardsdatascience.com/vision-transformers-explained-a9d07147e4c8)
	- [Jupyter Notebook](https://github.com/lanl/vision_transformers_explained/blob/main/notebooks/VisionTransformersExplained.ipynb)
- [Attention for Vision Transformers, Explained](https://towardsdatascience.com/attention-for-vision-transformers-explained-70f83984c673)
	- [Jupyter Notebook](https://github.com/lanl/vision_transformers_explained/blob/main/notebooks/AttentionExplained.ipynb)
 - [Position Embeddings for Vision Transformers, Explained](https://towardsdatascience.com/position-embeddings-for-vision-transformers-explained-a6f9add341d5)
 	- [Jupyter Notebook](https://github.com/lanl/vision_transformers_explained/blob/main/notebooks/PositionEmbeddingExplained.ipynb)
 - [Tokens-to-Token Vision Transformers, Explained](https://towardsdatascience.com/tokens-to-token-vision-transformers-explained-2fa4e2002daa)
	- [Jupyter Notebook](https://github.com/lanl/vision_transformers_explained/blob/main/notebooks/TokensToTokenViTExplained.ipynb)

This project were developed by **Skylar Callis** while working as a post-bachelors student at [Los Alamos National Laboratory (LANL)](https://www.lanl.gov/?source=globalheader) from 2022 - 2024. To see what they are up to these days, visit [Skylar's Website ](https://skylar-jean.com).

The Vision Transformers Explained code has been approved by LANL for a BSD-3 open source license under O#4693. The written components have been approved for release as LA-UR-23â€“33876.

The GitHub page for this code can be found [here](https://github.com/lanl/vision_transformers_explained).